\documentclass{scrreprt}

\usepackage{aligned-overset}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage[shortlabels]{enumitem}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{physics}
\usepackage{tabularx}
\usepackage{titling}
\usepackage{fancyhdr}
\usepackage{xfrac}
\usepackage{pgfplots}

\definecolor{light-gray}{gray}{.9}

\pgfplotsset{compat = newest}
\usetikzlibrary{intersections}
\usetikzlibrary{patterns}
\usepgfplotslibrary{fillbetween}

\author{Karsten Lehmann}
\date{SoSe 2021}
\title{Übung 08 Analysis - Weiterführende Konzepte}

\pagestyle{fancy}
\fancyhf{}
\lhead{\thetitle}
\rhead{\theauthor}
\lfoot{\thedate}
\rfoot{Seite \thepage}

\newcommand\skalprod[1]{\left\langle #1 \right\rangle}
\newcommand\nnorm[1]{\left\lvert\left\lvert\left\lvert #1 \right\rvert\right\rvert\right\rvert}

\begin{document}
\section*{Partielle Ableitungen}

$f \colon \mathbb{R}^N \to \mathbb{R}^M$ in $x \in \mathbb{R}^N$ differenzierbar
\[
  \iff \exists \: T \in \mathcal{L}\qty(\mathbb{R}^N, \mathbb{R}^M),
  r \colon \mathbb{R}^N \to \mathbb{R}^M \colon f(x + h) =
  f(x) + \underset{f'(x)}{\underbrace{T}}(h) + r(h),
  \frac{r(h)}{\norm{h}} \overset{h \to 0}\longrightarrow 0
\]
\[
  f'(x) \in \mathcal{L}\qty(\mathbb{R}^N, \mathbb{R}^M),
  f' \colon d_f \subseteq \mathbb{R}^N \to \mathcal{L}\qty(\mathbb{R}^N, \mathbb{R}^M)
\]
Auf $\mathbb{R}^N, \mathbb{R}^M$ seien die Standardbasen gegeben.
Dann gibt es genau eine Matrix $A \in \mathbb{R}^{M \times N}$ mit
$y = \underset{\makebox[0pt]{$J_f(x_0)$ Jacobi-Matrix}}{\underbrace{A}} \cdot x$
wobei $x$ Koordinatenvektor von $x$ und $y$ Koordinatenvektor von $f'(x_0)$
bezüglich der Standardbasen ist.

Wir betrachten zunächst $f \colon \mathbb{R}^N \to \mathbb{R}$ und
Richtungsableitungen für $v \in \mathbb{R}^N, v \ne 0$.
Sei $g(t) = f(x_0 + tv), g \colon \mathbb{R} \to \mathbb{R}$.
\begin{flalign*}
  \text{Falls } g'(0) &= \lim_{t \to 0} \frac{1}{t}\qty(g(t) - g(0)) & \\
  &= \lim_{t \to 0} \frac{1}{t} \qty(f(x_0 + tv) - f(x_0)) \text{ existiert,}
\end{flalign*}
wird $d_v f\qty(x_0) \coloneqq \frac{f\qty(x_0)}{dv} = g'(0)$ gesetzt.

Für $v = e_k$ ergeben sich die sogenannten partiellen Ableitungen:
\begin{flalign*}
  \frac{df}{d_{x_x}}\qty(x_0) &= \lim_{t \to 0} \frac{1}{t} \qty(f\qty(x_0 + t_{e_k}) - f\qty(x_0)) & \\
  &= \lim_{t \to 0} \frac{1}{t}
  \qty(\underset{g(t)}{\underbrace{f\qty(x_{0_1}, \ldots, x_{0_{k - 1}}, x_{0_k} + t, x_{0_{k + 1}}, x_{0_N})}}
  - f(x_0))
\end{flalign*}
Falls $f$ in $x_0$ differenzierbar ist, existieren
$\frac{d_f}{d_{x_k}}\qty(x_0), k = 1, \ldots, N$
\[
  D_{f(x)} \coloneqq \qty(\frac{d}{d_{x_1}}, \ldots, \frac{d}{d_{x_N}})f\qty(x_0) \quad\text{(Gradient)}
\]
$\forall h \in \mathbb{R}^N \colon f'\qty(x_0)(h) = \skalprod{D_{f\qty(x_0)}, h}
= \underset{J_f\qty(x_0)}{\underbrace{D_{f\qty(x_0)}^T}} \cdot h$

Zurück zu $f = \qty(_1, \ldots, f_M) \colon \mathbb{R}^N \to \mathbb{R}^M$.
$J_f\qty(x_0) = \begin{pmatrix}
  \frac{d}{d_{x_1}}f_1 & \ldots  & \frac{d}{d_{x_N}}f_1 \\
  \vdots & \vdots & \vdots \\
  \frac{d}{d_{x_1}}f_M & \ldots & \frac{d}{d_{x_N}}f_M
\end{pmatrix}\qty(X_0)$

Die Jacobi-Matrix ist nicht die Ableitung, sondern die Abbildungsmatrix
der Ableitung an der Stelle $x_0$ unter Verwendung der Standardbasen.

\paragraph{Aufgabe 1} Geben Sie von den folgenden Ausdrücken $f(x)$ den größten Bereich
$D(f) \subseteq \mathbb{R}^N$, für den $f$ definiert ist.
Wie lautet der Existenzbereich $D(f') \subseteq D(f)$ der Ableitung $f'$.
Geben Sie die zugehörige Jacobi-Matrix $J_f$ an.
\begin{enumerate}[a)]
\item $f\qty(x_1, x_2) = \sqrt{2x_1 + 3x_1x_2 + 4x_2}$
\item
\item $f\qty(x_1, x_2) = \qty(\tan\qty(x_1) + x_2^4, \ln\qty(x_1 + x_2))$
  \subparagraph{Lsg.} $f \colon D_f \subseteq \mathbb{R}^2 \to \mathbb{R}^2$
  \begin{flalign*}
    f\qty(x_1, x_2) &= \begin{pmatrix}
      \tan\qty(x_1) + x_2^4 \\
      \ln\qty(x_1 + x_2)
    \end{pmatrix} & \\
    \Rightarrow &D_f = \qty{x = \qty(x_1, x_2) \in \mathbb{R}^2 {\Big |}
      \underset{\tan(\ldots)}{\underbrace{x_1 \ne \frac{\pi}{2} + k\pi, k \in \mathbb{Z}}}
      , \underset{\ln(\ldots)}{\underbrace{x_1 + x_2 > 0}}}
    \subseteq \mathbb{R}^2 \: \text{ist eine offene Menge}
  \end{flalign*}
  \[
    x \in D_f \colon J_f (x) = \begin{pmatrix}
      \frac{1}{\cos^2 x_1} & 4 x_2^3 \\
      \frac{1}{x_1 + x_2} & \frac{1}{x_1 + x_2}
    \end{pmatrix}
  \]
  $x \mapsto J_f(x)$ ist stetig auf $D_f = D_{f'} \Rightarrow f$ ist auf
  $D_{f'} = D_f$ stetig differenzierbar.
  \[
    \qty(\text{Die Jacobi-Matrix ist stetig, weil }
     x \mapsto \frac{d_{f_1}(x)}{dx_1}, \frac{d_{f_1}(x)}{dx_2}, \frac{d_{f_2}(x)}{dx_1}, \frac{d_{f_2}(x)}{dx_2},
    \text{ stetig sind})
  \]

\item $f\qty(x_1, x_2) = \qty(x_1, x_2, e^{x_1^2 + 4 x_2})$
  \subparagraph{Lsg.} $f \colon D_f \subseteq \mathbb{R}^2 \to \mathbb{R}^3, D_f = \mathbb{R}^2$
  \[
    f\qty(x_1, x_2) = \begin{pmatrix}
      x_1 \\
      x_2 \\
      e^{x_1^2 + 4x_2}
    \end{pmatrix},
    J_f(x) = \begin{pmatrix}
      1 & 0 \\
      0 & 1 \\
      2 x_1 e^{x_1^2 + 4 x_2} & 4e^{x_1^2 + 4x_2}
    \end{pmatrix}
  \]
  $f$ ist für alle $x \in \mathbb{R}^2$ stetig differenzierbar, da
  $x = \qty(x_1, x_2) \mapsto J_f(x)$ stetig Abbildbar ist.

  \textbf{Achtung:} Generell reicht die Existenz des Gradienten oder der
  Jacobi-Matrix reicht nicht dafür aus, dass die Funktion differenzierbar ist.
  Die Bedingung, dass die Abbildung von $x$ in die Jacobi-Matrix stetig ist, ist
  eine hinreichende Bedingung, dass die Funktion differenzierbar und sogar stetig
  differenzierbar ist.
\end{enumerate}

\newpage
\section*{Tangentialhyperebene und affin-lineare Approximation}
\paragraph{Aufgabe 3} Sei $f \colon D(f) \subseteq \mathbb{R}^N \to \mathbb{R}$
in $x_0 \in D(f)$ differenzierbar.
Dann gibt es eine Funktion $r \colon \mathbb{R}^N$ mit
\[
  f(x_0 + h) = f(x_0) + \skalprod{\nabla f(x_0), h} + r(h) \text{ und }
  \lim_{h \to 0} \frac{r(h)}{\norm{h}} = 0
\]
Damit ist die Funktion
\[
  t_{f,x_0}(x) \coloneqq f(x_0) + \skalprod{\nabla f(x_0), x - x_0}, x \in \mathbb{R}^N
\]
eine affin-lineare Approximation von $f$ in $x_0$.
Dies stellt eine Verallgemeinerung der Tangenten im Fall $N = 1$ dar.
Der Graph der Funktion $t_{f,x_0}$
\[
  \mathbb{T}_{f, x_0} \coloneqq \qty{\qty(x, t_{x_0}(x)) \in \mathbb{R}^{N + 1} {\Big |} x \in \mathbb{R}^N}
  = \qty{(x, y) \in \mathbb{R}^{N + 1} {\Big |} y = f(x_0) + \skalprod{\nabla f(x_0), x - x_0}, x \in \mathbb{R}^N}
\]
wird \textit{Tangentialhyperebene} von $f$ in $x_0$ genannt.
Sie wird von den $N$ Vektoren $\qty(e_k, \partial_k, f(x_0)), k = 1, \ldots, N$
aufgespannt und verläuft durch den Punkt $(x_0, f(x_0))$.
Normalenvektor $n \in \mathbb{R}^{N + 1}$ dieser Ebene ist
\[
  n = (-\nabla f(x_0), 1) \text{ bzw. } n = (\nabla f(x_0), -1)
\]
Damit erlaubt $\mathbb{T}_{f, x_0}$ die Darstellung
\begin{flalign*}
  \mathbb{T}_{f, x_0} &= \qty{(x, y) \in \mathbb{R}^{N + 1} {\Big |} \skalprod{\qty(\nabla f\qty(x_0), -1), (x, y)}
    = \skalprod{(\nabla f \qty(x_0), -1), \qty(x_0, f\qty(x_0))}} & \\
  &= \qty{(x, y) \in \mathbb{R}^{N + 1} {\Big |} \skalprod{n, (x, y)} = \skalprod{n, \qty(x_0, f\qty(x_0))}}
\end{flalign*}
Wobei $\skalprod{., .}$ das Euklidische Skalarprodukt im $\mathbb{R}^{N + 1}$
bezeichnet.
Wir betrachten die Funktion $f \colon \mathbb{R}^2 \to \mathbb{R}$ mit
$f\qty(x_1, x_2) = \sin\qty(x_1 + x_2) - \ln\qty(1 + x_1^2 + x_2^2)$.

\subparagraph{Vorbertrachtung} $f \colon D_f \subseteq \mathbb{R}^N \to \mathbb{R}$
sei in $x_0 \in D_f$ differenzierbar.
\begin{align*}
  \Rightarrow f(\underset{= x}{\underbrace{x_0 + h}})
  &= f\qty(x_0) + \skalprod{\nabla f\qty(x_0), h}
    + r(h) \quad \text{mit } \frac{r(h)}{\norm{h}} \overset{h \to 0}\longrightarrow 0 & \\
  f(x) &= \underset{\makebox[0pt]{$t_{f, x_0}(x)$ affin-lineare lokale Approximation von $f$ in $x_0$}}{
         \underbrace{f\qty(x_0) + \skalprod{\nabla f\qty(x_0), x - x_0}}
         } + \ldots
\end{align*}
($t_{f,x_0}$ ist die Tangente)
\[
  \mathbb{T}_{f, x_0} = \qty{\qty(x, t_{f, x_0}(x)) \in \mathbb{R}^{N + 1} {\Big |} x \in \mathbb{R}^N}
\]
ist Tangential-(hyper)-ebene von $f$ in $x_0$, die von
$\qty(e_k, \frac{df}{dx_x}(x_0)), k = 1, \ldots, N$ aufgespannt wird.
Normalenvektor ist $n = \pm \qty(\nabla f\qty(x_0))$.

\newpage
\begin{enumerate}[a)]
\item Berechnen Sie den Gradienten von $f$.
  Ist $f$ auf $\mathbb{R}^2$ differenzierbar?

  \subparagraph{Lsg.}
  $f\qty(x_1, x_2) = \sin\qty(x_1 + x_2) - \ln\qty(1 + x_1^2 + x_2^2), x \in D_f = \mathbb{R}^2$.
  \[
    \nabla f\qty(x_1, x_2) = \begin{pmatrix}
      \frac{df}{dx_1}(x) \\
      \frac{df}{dx_2}(x)
    \end{pmatrix}
    \underset{\makebox[0pt]{$f\qty(x_1, x_2) = f\qty(x_2, x_1)$}}{\underset{\Big \uparrow}{=}}
    \begin{pmatrix}
      \cos\qty(x_1 + x_2) - \frac{1 \cdot 2 x_1}{1 + x_1^2 + x_2^2} \\
      \cos\qty(x_1 + x_2) - \frac{1 \cdot 2 x_2}{1 + x_1^2 + x_2^2}
    \end{pmatrix}
  \]

  $x \mapsto \nabla f\qty(x_1, x_2)$ ist auf $D_f = \mathbb{R}^2$ stetig.
  $\Rightarrow f$ ist auf $\mathbb{R}^2$ stetig differenzierbar.
  \[
    J_f\qty(x_1, x_2) = \begin{pmatrix}
      \cos\qty(x_1 + x_2) - \frac{2 x_1}{1 + x_1^2 + x_2^2} &
      \cos\qty(x_1 + x_2) - \frac{2 x_2}{1 + x_1^2 + x_2^2}
    \end{pmatrix}
  \]

\end{enumerate}
\end{document}