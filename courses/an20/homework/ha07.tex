\documentclass{scrreprt}

\usepackage{aligned-overset}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage[shortlabels]{enumitem}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{physics}
\usepackage{tabularx}
\usepackage{titling}
\usepackage{fancyhdr}
\usepackage{xfrac}
\usepackage{pgfplots}

\pgfplotsset{compat = newest}
\usepgfplotslibrary{fillbetween}

\author{}
\date{SoSe 2021}
\title{Hausaufgabe 07 \\Analysis - Weiterführende Konzepte}

\setlength{\headheight}{26pt}
\pagestyle{fancy}
\fancyhf{}
\lhead{\thetitle}
\rhead{\theauthor}
\lfoot{\thedate}
\rfoot{Seite \thepage}

\newcommand\sign[1]{\text{sign}\qty(#1)}

\begin{document}
\paragraph{Hausaufgabe 1}
\begin{enumerate}[1)]
\item Die Räume $\mathbb{R}^N$ und $\mathbb{R}^M$ seien mit der
  $\norm{\cdot}_{\infty}$-Norm versehen.
  Beweisen Sie, dass sich als Operatornorm von $A \in \mathbb{R}^{M \times N}$
  die sogenannte \textit{Zeilensummennorm} ergibt:
  \[
    \norm{A} = \max_{j = 1, \ldots, M} \sum_{k = 1}^N \abs{a_{jk}}
    \text{ für alle } A \in \mathcal{L}\qty(\mathbb{R}^N, \mathbb{R}^M)
  \]
  \textbf{Anleitung:} Zeigen Sie
  $\norm{A \cdot x}_{\infty} \leq \max_{j = 1, \ldots, M} \sum_{k = 1}^N \abs{a_{jk}}$
  für alle $x \in \mathbb{R}^N$ mit $\norm{x}_{\infty} \leq 1$.
  Wählen Sie zunächst geeignete $x^j \in \mathbb{R}^N$ mit
  $\norm{x}_{\infty} = 1$, so dass
  $\max_{j = 1, \ldots, M} \underset{\makebox[0pt]{Betragssumme der $j$-ten Zeile}}{\underbrace{\sum_{k = 1}^N \abs{a_{jk}}}}
  \leq \max_{j = 1, \ldots, M} \norm{A \cdot x^j}_{\infty}$
  gilt.

  \subparagraph{Lsg.} $\norm{x}_{\infty} = \max\qty(\abs{x_1}, \ldots, \abs{x_N})$.
  Aus $\norm{x}_{\infty} \leq 1$ folgt $\abs{x_k} \leq 1$ für $k = 1, \ldots, N$
  und für alle
  \colorbox{yellow}{$i = 1, \ldots, M \colon \sum_{k = 1}^N a_{ik} \cdot x_k
  \leq \sum_{k = 1}^N \abs{a_{ik} \cdot x_k} \leq \sum_{k = 1}^N \abs{a_{ik}}$}.
  Somit gilt:
  \[
    \norm{A \cdot x}_{\infty} = \max_{j = 1, \ldots, M} \sum_{k = 1}^N a_{jk} \cdot x_k
    \leq \max_{j = 1, \ldots, M} \sum_{k = 1}^N \abs{a_{jk}}
  \]
  Sei nun $x^j \in \mathbb{R}^N$ mit $x^j = \begin{pmatrix} \sign{a_{j1}} \\ \vdots \\ \sign{a_{jN}} \end{pmatrix}$.
  Dann ist $\norm{x^j}_{\infty} = 1$ und
  \[
    \norm{A \cdot x^j}_{\infty} = \begin{pmatrix}
      \sum_{k = 1}^N a_{1k} \cdot x_k \\
      \vdots \\
      \sum_{k = 1}^N a_{jk} \cdot x_k \\
      \vdots \\
      \sum_{k = 1}^N a_{Mk} \cdot x_k \\
    \end{pmatrix}
    = \begin{pmatrix}
      \sum_{k = 1}^N a_{1k} \cdot x_k \\
      \vdots \\
      \sum_{k = 1}^N a_{jk} \cdot \sign{a_{jk}} \\
      \vdots \\
      \sum_{k = 1}^N a_{Mk} \cdot x_k \\
    \end{pmatrix}
    = \begin{pmatrix}
      \sum_{k = 1}^N a_{1k} \cdot x_k \\
      \vdots \\
      \sum_{k = 1}^N \abs{a_{jk}} \\
      \vdots \\
      \sum_{k = 1}^N a_{Mk} \cdot x_k \\
    \end{pmatrix}
  \]
  Wie \colorbox{yellow}{bereits gezeigt} ist
  $\sum_{k = 1}^N a_{ik} \cdot x_k\leq \sum_{k = 1}^N \abs{a_{ik}}$,
  somit ist $\max\norm{A \cdot x^j}_{\infty} = \sum_{k = 1}^N \abs{a_{jk}}$
  und
  $\max_{j = 1, \ldots, M} \sum_{k = 1}^N \abs{a_{jk}} = \max_{j = 1, \ldots, M} \norm{A \cdot x^j}_{\infty}$.
  \[
    \Rightarrow \norm{A}_{\infty} = \sup\qty{\norm{A \cdot x}_{\infty} {\Big |} \norm{x}_{\infty} \leq 1 }
  \]
  \newpage

\item Die Menge $\mathbb{R}^{N \times N}$ der reellen $N \times N$-Matrizen sei
  mit einer Norm $\norm{\cdot}$ versehen, z.B. eine der üblichen Operatornormen
  oder der Frobenius-Norm.
  Beweisen Sie, dass die Teilmenge der invertierbaren Matrizen eine offene Menge
  in $\qty(\mathbb{R}^{N \times N}, \norm{\cdot})$ ist.
  Argumentieren Sie unter der Verwendung der Determinanten quadratischer
  Matrizen.

  \subparagraph{Lsg.} Die Determinante ist eine stetige Abbildung
  $\det \colon \mathbb{R}^{N \times N} \to \mathbb{R}$.
  Für alle invertierbaren Matizen $A \in \mathbb{R}^{N \times N}$
  gilt $\det A \ne 0$.
  Nun existiert für jedes $x \in \mathbb{R} \setminus \qty{0}$
  eine Matrix $A \in \mathbb{R}^{N \times N}$ mit
  $\det A = X$.
  Die Menge $\mathbb{R} \setminus \qty{0}$ ist offen und aus
  Proposition 6.3.3 der Vorlesung
  (``Stetige Urbilder offener Mengen sind offen'')
  folgt, dass die Menge der invertierbaren Matrizen in
  $\mathbb{R}^{N \times N}w$ offen ist.
\end{enumerate}

\paragraph{Hausaufgabe 2} Der Raum $\mathbb{R}^{N \times N}$ sei durch eine
Matrixnorm normiert.
Ermitteln Sie von $f \colon \mathbb{R}^{N \times N} \to \mathbb{R}^{N \times N}$
mit $f(X) \coloneqq X^2$ die Weierstraßsche Zerlegungsformel für ein festes
$X_0 \in \mathbb{R}^{N \times N}$.
Bestimmen Sie daraus die Ableitung $f'(X_0)$.

\subparagraph{Lsg.}

Es gilt
\begin{align*}
  f(x_0 + h) - f(x_0) &= (x_0 + h)^2 - x_0^2 = x_0^2 + 2x_0h + h^2 - x_0^2 \\
                      &= \underset{h \mapsto 2x_0h \text{ ist linear}}{\underbrace{2x_0h}} +
                        \underset{r(h)}{\underbrace{h^2}}
\end{align*}
$\Rightarrow f'(X_0)(h) = 2X_0h$

\paragraph{Hausaufgabe 3} Beweisen Sie, dass die Fréchet-Ableitung einer
differenzierbaren Funktion $f \colon D(f) \subseteq X \to Y$
in einem Punkt $x \in D(f)$ eindeutig bestimmt ist, d.h., gibt es zwei
Zerlegungen
\[
  f(x + h) = f(x) + Th + r_1(h) \text{ und } f(x + h) = f(x) + Sh + r_2(h)
\]
mit $T, S \in \mathcal{L}(X, Y)$ und $r_k \colon X \to Y$, für die
$\lim_{h \to 0} \frac{\norm{r_k(h)}_Y}{\norm{h}_X} = 0$ gilt, so stimmen
$T$ und $S$ überein.

\subparagraph{Lsg.} $f(x) + Th + r_1(h) = f(x) + Sh + r_2(h)$
\begin{align*}
  \Rightarrow \norm{T - S} &= \frac{\norm{r_2(h) - r_1(h)}}{\norm{h}} = - \frac{\norm{r_1(h) + r_2(h)}}{\norm{h}}
                             \leq -\frac{\norm{r_1(h)}}{\norm{h}} + \frac{\norm{r_2(h)}}{\norm{h}} \\
  \overset{h \to 0}&= 0 \\
  \Rightarrow T - S = 0 &\Rightarrow T = S
\end{align*}

\end{document}
